{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine translation using LSTM cells on Sequence-to-Sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence-to-Sequence models try to map input sequences to target/output sequences. It is still a prediction problem, but instead of classifying the input to a single or multiple class, the model predicts tokens one by one till the end of the sequence, thereby generating an output sequence.\n",
    "\n",
    "LSTMs are Long-short Term memory networks. They are most commonly used in long sequence problems, as they seem to be good at preserving the history of tokens.\n",
    "\n",
    "Here we will apply LSTM cells in the Sequence-to-Sequence networks on a character level for Machine translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While working on Multiple languages, it is highly recommended to use `utf-8` encoding so that the non-ascii characters are read properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resource\\en_de.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.\\tGeh.',\n",
       " 'Hi.\\tHallo!',\n",
       " 'Hi.\\tGrüß Gott!',\n",
       " 'Run!\\tLauf!',\n",
       " 'Run.\\tLauf!',\n",
       " 'Wow!\\tPotzdonner!',\n",
       " 'Wow!\\tDonnerwetter!',\n",
       " 'Fire!\\tFeuer!',\n",
       " 'Help!\\tHilfe!',\n",
       " 'Help!\\tZu Hülf!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the sentence before the `\\t` is in english and the part after is the translation in German language. Now, we must extract them and store them as input and target values for the ML model to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(data):\n",
    "    ip,op = line.split('\\t')\n",
    "    input_texts.append(ip)\n",
    "    target_texts.append('\\t' + op + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you could see here, we have deliberately concatenated the `\\t` at the front and `\\n` at the end. These are called START and END tokens. Its more common nowadays to use `<START>` and `<END>` tokens, so its unambiguous. We just use `\\t` and `\\n` for simplicity.\n",
    "\n",
    "Since we will be working on character-level, the `input_chars` and `target_chars` extract the character level vocabulary from the input, target texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars = set([l for w in input_texts for l in w])\n",
    "target_chars = set([l for w in target_texts for l in w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence-to-Sequence adopts the architecture of Encoder-decoder network. In training, the input sequences are fed into an encoder-network, and the target sentences to a decoder-network. In-order to do so, we must initialise the shape of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to train all the input sequences in the same network, and not all the sequences are of same length, So we must get the maximum length of input and target sequences for the encoder and decoder sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each character token in the sequence is represented by one-hot encoding, thus the length of each token (`num_enc_tokens`, `num_dec_tokens`) is the size of the respective vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_enc_tokens = len(input_chars)\n",
    "num_dec_tokens = len(target_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one-hot encoding, we must create character-index pairs, so that we can map back and forth. Just make sure that the order of the `input_chars` and `target_chars` are preserved till the end, any change in the list order might lead to improper mapping to their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char2idx = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "target_char2idx = dict([(char, i) for i, char in enumerate(target_chars)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reverse lookup is not needed during training. But, this might come in handy when we do Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_idx2char = dict([(i, char) for i, char in enumerate(input_chars)])\n",
    "target_idx2char = dict([(i, char) for i, char in enumerate(target_chars)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inorder to fill the encoder - decoder network, the following step instantiates zero matrices with defined shapes for input to encoder input, decoder input and decoder output. The shape of the matrix is the length of the training data, maximum length of the sequence, and the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_enc_tokens),dtype='float32')\n",
    "decoder_input_data = np.zeros((len(target_texts), max_decoder_seq_length, num_dec_tokens),dtype='float32')\n",
    "decoder_target_data = np.zeros((len(target_texts), max_decoder_seq_length, num_dec_tokens),dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the empty matrices are created, `encoder_input_data`, `decoder_input_data`, `decoder_ouput_data` have to be filled with data from the english-german training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[idx, t, input_char2idx[char]] = 1.\n",
    "    encoder_input_data[idx, t + 1:, input_char2idx[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[idx, t, target_char2idx[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[idx, t - 1, target_char2idx[char]] = 1.\n",
    "    decoder_input_data[idx, t + 1:, target_char2idx[' ']] = 1.\n",
    "    decoder_target_data[idx, t:, target_char2idx[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_units = 128 # The latent units are nothing but the hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, num_enc_tokens))\n",
    "encoder_lstm = LSTM(latent_units, return_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the activation function in the final layer (`decoder_dense`) is `softmax` activation. Since, it predicts the probability of the next character and it must sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, num_dec_tokens))\n",
    "decoder_lstm = LSTM(latent_units, return_state=True, return_sequences=True)\n",
    "decoder_dense = Dense(num_dec_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sant_si\\envs\\env36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs, _,_ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sant_si\\envs\\env36\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\sant_si\\envs\\env36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 1.5068 - accuracy: 0.6427 - val_loss: 1.3913 - val_accuracy: 0.6150\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 1.1251 - accuracy: 0.6936 - val_loss: 1.1383 - val_accuracy: 0.7019\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.9207 - accuracy: 0.7558 - val_loss: 0.9502 - val_accuracy: 0.7515\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.7937 - accuracy: 0.7800 - val_loss: 0.8557 - val_accuracy: 0.7641\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.7265 - accuracy: 0.7954 - val_loss: 0.8025 - val_accuracy: 0.7760\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.6833 - accuracy: 0.8049 - val_loss: 0.7697 - val_accuracy: 0.7838\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.6508 - accuracy: 0.8132 - val_loss: 0.7427 - val_accuracy: 0.7882\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.6237 - accuracy: 0.8213 - val_loss: 0.7194 - val_accuracy: 0.7963\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.6008 - accuracy: 0.8271 - val_loss: 0.7007 - val_accuracy: 0.8000\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.5803 - accuracy: 0.8326 - val_loss: 0.6914 - val_accuracy: 0.8016\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.5632 - accuracy: 0.8374 - val_loss: 0.6681 - val_accuracy: 0.8089\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.5475 - accuracy: 0.8415 - val_loss: 0.6654 - val_accuracy: 0.8093\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5331 - accuracy: 0.8457 - val_loss: 0.6479 - val_accuracy: 0.8159\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.5202 - accuracy: 0.8495 - val_loss: 0.6386 - val_accuracy: 0.8165\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.5084 - accuracy: 0.8529 - val_loss: 0.6285 - val_accuracy: 0.8197\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4972 - accuracy: 0.8562 - val_loss: 0.6200 - val_accuracy: 0.8230\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4873 - accuracy: 0.8588 - val_loss: 0.6122 - val_accuracy: 0.8249\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4772 - accuracy: 0.8617 - val_loss: 0.6071 - val_accuracy: 0.8261\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4681 - accuracy: 0.8641 - val_loss: 0.6033 - val_accuracy: 0.8271\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4593 - accuracy: 0.8670 - val_loss: 0.5963 - val_accuracy: 0.8281\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4508 - accuracy: 0.8692 - val_loss: 0.5906 - val_accuracy: 0.8310\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4426 - accuracy: 0.8715 - val_loss: 0.5869 - val_accuracy: 0.8318\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4350 - accuracy: 0.8736 - val_loss: 0.5831 - val_accuracy: 0.8327\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4277 - accuracy: 0.8760 - val_loss: 0.5775 - val_accuracy: 0.8343\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4208 - accuracy: 0.8783 - val_loss: 0.5771 - val_accuracy: 0.8343\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4137 - accuracy: 0.8799 - val_loss: 0.5750 - val_accuracy: 0.8357\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4070 - accuracy: 0.8823 - val_loss: 0.5722 - val_accuracy: 0.8369\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4010 - accuracy: 0.8839 - val_loss: 0.5762 - val_accuracy: 0.8361\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3951 - accuracy: 0.8855 - val_loss: 0.5658 - val_accuracy: 0.8392\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3891 - accuracy: 0.8875 - val_loss: 0.5605 - val_accuracy: 0.8417\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3835 - accuracy: 0.8890 - val_loss: 0.5599 - val_accuracy: 0.8426\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3781 - accuracy: 0.8907 - val_loss: 0.5656 - val_accuracy: 0.8417\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3726 - accuracy: 0.8923 - val_loss: 0.5600 - val_accuracy: 0.8426\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3672 - accuracy: 0.8939 - val_loss: 0.5592 - val_accuracy: 0.8421\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3625 - accuracy: 0.8953 - val_loss: 0.5615 - val_accuracy: 0.8424\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3576 - accuracy: 0.8966 - val_loss: 0.5598 - val_accuracy: 0.8455\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3531 - accuracy: 0.8977 - val_loss: 0.5547 - val_accuracy: 0.8453\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3480 - accuracy: 0.8993 - val_loss: 0.5542 - val_accuracy: 0.8461\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3436 - accuracy: 0.9006 - val_loss: 0.5553 - val_accuracy: 0.8462\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3389 - accuracy: 0.9019 - val_loss: 0.5571 - val_accuracy: 0.8466\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3349 - accuracy: 0.9031 - val_loss: 0.5550 - val_accuracy: 0.8461\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3305 - accuracy: 0.9046 - val_loss: 0.5524 - val_accuracy: 0.8472\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3263 - accuracy: 0.9058 - val_loss: 0.5560 - val_accuracy: 0.8476\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3222 - accuracy: 0.9070 - val_loss: 0.5555 - val_accuracy: 0.8475\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3180 - accuracy: 0.9081 - val_loss: 0.5568 - val_accuracy: 0.8478\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3143 - accuracy: 0.9091 - val_loss: 0.5554 - val_accuracy: 0.8494\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3104 - accuracy: 0.9102 - val_loss: 0.5554 - val_accuracy: 0.8491\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3066 - accuracy: 0.9114 - val_loss: 0.5608 - val_accuracy: 0.8480\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3031 - accuracy: 0.9124 - val_loss: 0.5573 - val_accuracy: 0.8482\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3000 - accuracy: 0.9132 - val_loss: 0.5598 - val_accuracy: 0.8483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2485945fa58>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/en2de.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_state_h = Input(shape=(latent_units,))\n",
    "input_state_c = Input(shape=(latent_units,))\n",
    "decoder_input_states = [input_state_h, input_state_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_input_states)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model([decoder_inputs] + decoder_input_states, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Run input seq through encoder model\n",
    "    states = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, num_dec_tokens))\n",
    "    target_seq[0, 0, target_char2idx['\\t']] = 1\n",
    "    \n",
    "    end_of_seq = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not end_of_seq:\n",
    "        output, h, c = decoder_model.predict([target_seq] + states)\n",
    "        predicted_char_idx = np.argmax(output[0, -1, :])\n",
    "        predicted_char = target_idx2char[predicted_char_idx]\n",
    "        decoded_sentence += predicted_char\n",
    "        \n",
    "        if (predicted_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            end_of_seq = True\n",
    "            \n",
    "        target_seq[0, 0, predicted_char_idx] = 1\n",
    "        states = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Gehlleeeeeneeennnntieeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Hallloullnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Hallloullnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Lausssssssssssssssssssssssssssssssssssssßsse?\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Lausssssssssssssssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Warteu unnnnnnnntttttttttttttttttttttttttttttt\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Warteu unnnnnnnntttttttttttttttttttttttttttttt\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Verörrrrssssssssssssssssssss!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Hulle, nninsssstssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Hulle, nninsssstssssssssssssssssssssssssssssss\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Hautllllllllllßtt?\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Warte uunnnnnnststtttttttttttttttttttttttttttt\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Warte uunnnnnnnttttttttttttttttttttttttttttttt\n",
      "-\n",
      "Input sentence: Begin.\n",
      "Decoded sentence: Biellfeetttteeeeeeeeeeeeettreeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Gehtrreeeeeeeeeeeeeeeieeeeeeeeeeeö............\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Halll,, uundaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: Beeilllfffttttttttttttttttttttttttrttteeeeeeee\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: Beeilllfffttttttttttttttttttttttttrttteeeeeeee\n",
      "-\n",
      "Input sentence: I hid.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I hid.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Ich hhhnhhhhhhhhhhkokkkmmmmmmmmmmmmmenniennnnn\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Ichhhhhkkmmmmmeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhkkonkkkk?kkk\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhkkonkkkk?kkk\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Niemmeerrrrchhhccceeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Warse tuuutttttttttttttttttttttttttttttttttttt\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Warse tuuutttttttttttttttttttttttttttttttttttt\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Beiellgeeeeeee!\n",
      "\n",
      "-\n",
      "Input sentence: Ask me.\n",
      "Decoded sentence: Fraungnnnngggggggggggggggggrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input sentence: Ask me.\n",
      "Decoded sentence: Fraungnnnngggggggggggggggggrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input sentence: Ask me.\n",
      "Decoded sentence: Fraungnnnngggggggggggggggggrrrrrrrrrrrrrrrrrrr\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Anggt!o!!!!!!!?\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Anggt!o!!!!!!!?\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Verrrrrrrrriirtrrrrrrrrrrrrrrrrrrrrrrrrrrrrrre\n",
      "-\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Isst emhammmmmmnnennnnnnnnnnnnnnnnnnnnn.......\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence: Iss heinnnnnnnnnnnnnnnnnnnnnnnnnttttteeeeeeeee\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence: Iss heinnnnnnnnnnnnnnnnnnnnnnnnnttttteeeeeeeee\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Verrrrrrrörrrrrrrrsssssss.\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Verrrrrrrörrrrrrrrsssssss.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Gehtrreeeeeeeeeeeeeeieeeeeeeeeeeeö!.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Versisstseeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Versisstseeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Versisstseeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Hallund?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Hallund?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Hallund?\n",
      "\n",
      "-\n",
      "Input sentence: He ran.\n",
      "Decoded sentence: Er rinnnnnnnnchtetttttttttttttteeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: He ran.\n",
      "Decoded sentence: Er rinnnnnnnnchtetttttttttttttteeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Steieee ereeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Steieee ereeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Ummammmml!\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Ummammmml!\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Ummammmml!\n",
      "\n",
      "-\n",
      "Input sentence: I care.\n",
      "Decoded sentence: Ichhhhkkmmmmmeeeeeeeeeeeeeeeeeeeeeeeteeeeeeeem\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Ich hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Ich hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Ich hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Ich hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Ich hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I fled.\n",
      "Decoded sentence: Ichhhhhkkommmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
      "-\n",
      "Input sentence: I fled.\n",
      "Decoded sentence: Ichhhhhkkommmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhkkommmmmmmmmmmmmmmmmmmmmm\n",
      "-\n",
      "Input sentence: I lied.\n",
      "Decoded sentence: Ichhhhhhhhhhhkommmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: Ichhhhhkkmmmmmeeeeeeeeeeeeeeeeeeeeeeemeeeeeeee\n",
      "-\n",
      "Input sentence: I paid.\n",
      "Decoded sentence: Ichhhhhkkmmmmmeeeeeeeeeeeeeeeeeeeeeeeeeeeommmm\n",
      "-\n",
      "Input sentence: I paid.\n",
      "Decoded sentence: Ichhhhhkkmmmmmeeeeeeeeeeeeeeeeeeeeeeeeeeeommmm\n",
      "-\n",
      "Input sentence: I sang.\n",
      "Decoded sentence: Ichhhhkkmmmmmmeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: I spit.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I spit.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I swim.\n",
      "Decoded sentence: Ichhhhkkommmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm\n",
      "-\n",
      "Input sentence: I wept.\n",
      "Decoded sentence: Ichhhhhkkommmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmne\n",
      "-\n",
      "Input sentence: I wept.\n",
      "Decoded sentence: Ichhhhhkkommmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmne\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I'm up.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: I'm up.\n",
      "Decoded sentence: Ichhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Jebzzeelieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Jebzzeelieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Jebzzeelieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Jebzzeelieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Jebzzeelieeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Wierst eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Wierst eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Wierst eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Das kauupppppppppppppftrerrrrrrrtttttttttttttt\n",
      "-\n",
      "Input sentence: Try it.\n",
      "Decoded sentence: Proboebrrrnnnn eelooieeeeeeeeeeecdeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: Wirer nschttteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Wirrechcct eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Why me?\n",
      "Decoded sentence: Warru fggttestttntttttttteeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Fraunngnnnggggggggggggggggggggggggggggggrrrrrr\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Fraunngnnnggggggggggggggggggggggggggggggrrrrrr\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Fraunngnnnggggggggggggggggggggggggggggggrrrrrr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: Fallgegllnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Seiet rreeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Seichtt eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Seichtt eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
